# PhÆ°Æ¡ng PhÃ¡p Sá»­ Dá»¥ng LangChain vá»›i Local Models cho Há»‡ Thá»‘ng RAG KhÃ¡ch Sáº¡n

## ğŸ“‹ Tá»•ng Quan

TÃ i liá»‡u nÃ y mÃ´ táº£ phÆ°Æ¡ng phÃ¡p xÃ¢y dá»±ng há»‡ thá»‘ng RAG (Retrieval-Augmented Generation) sá»­ dá»¥ng **LangChain** vá»›i **local embedding models** vÃ  **local LLM models** cho dataset khÃ¡ch sáº¡n.

---

## ğŸ¯ 1. CÃ“ THá»‚ Sá»¬ Dá»¤NG LANGCHAIN Vá»šI LOCAL MODELS KHÃ”NG?

### âœ… **CÃ“ - HoÃ n toÃ n cÃ³ thá»ƒ!**

LangChain há»— trá»£ ráº¥t tá»‘t cÃ¡c local models thÃ´ng qua:

#### **1.1 Local Embedding Models**
- **Ollama** (qua `langchain_community.embeddings.OllamaEmbeddings`)
- **Sentence Transformers** (qua `langchain_community.embeddings.HuggingFaceEmbeddings`)
- **BGE-M3, BGE-Large, Multilingual-E5** (qua HuggingFace)
- **Custom models** (qua wrapper tÃ¹y chá»‰nh)

#### **1.2 Local LLM Models**
- **Ollama** (`llama2`, `mistral`, `phi`, `gemma`, v.v.)
- **LM Studio** (qua API local)
- **vLLM** (qua local server)
- **Transformers** (trá»±c tiáº¿p load model)

---

## ğŸ§  2. LÃ€M THáº¾ NÃ€O Äá»‚ EMBEDDING HIá»‚U NGá»® NGHÄ¨A VÃ€ TÃŒM KIáº¾M ÄÃšNG?

### **2.1 Váº¥n Äá» ChÃ­nh**

Embedding cÃ³ thá»ƒ khÃ´ng hiá»ƒu Ä‘Ãºng ngá»¯ nghÄ©a náº¿u:
- âŒ Dá»¯ liá»‡u khÃ´ng Ä‘Æ°á»£c chuáº©n hÃ³a tá»‘t
- âŒ Chá»n sai embedding model
- âŒ KhÃ´ng cÃ³ context Ä‘áº§y Ä‘á»§
- âŒ Query khÃ´ng Ä‘Æ°á»£c xá»­ lÃ½ Ä‘Ãºng cÃ¡ch
- âŒ KhÃ´ng cÃ³ re-ranking sau khi search

### **2.2 PhÆ°Æ¡ng PhÃ¡p Cáº£i Thiá»‡n**

#### **A. Chuáº©n HÃ³a Dá»¯ Liá»‡u (Data Preprocessing)**

**Vá»›i dataset khÃ¡ch sáº¡n cá»§a báº¡n:**

1. **Káº¿t há»£p Ä‘a chiá»u dá»¯ liá»‡u:**
   ```
   Text = "TÃªn: {hotel_name} | "
          "MÃ´ táº£: {hotel_desc} | "
          "Äá»‹a chá»‰: {hotel_placedetails} | "
          "Khu vá»±c: {area_name} | "
          "ThÆ°Æ¡ng hiá»‡u: {brand_name} | "
          "Tá»« khÃ³a: {hotel_tag_keyword} | "
          "Háº¡ng: {hotel_rank} sao | "
          "GiÃ¡ trung bÃ¬nh: {hotel_price_average}"
   ```

2. **ThÃªm metadata quan trá»ng:**
   - ThÃ´ng tin phÃ²ng (room_name, room_view, room_acreage)
   - ThÃ´ng tin giÃ¡ (type_room_price, type_room_price_sale)
   - ThÃ´ng tin khu vá»±c (area_name, area_desc)
   - ThÃ´ng tin thÆ°Æ¡ng hiá»‡u (brand_name, brand_desc)

3. **Chuáº©n hÃ³a ngÃ´n ngá»¯:**
   - Loáº¡i bá» kÃ½ tá»± Ä‘áº·c biá»‡t thá»«a
   - Xá»­ lÃ½ encoding (UTF-8)
   - Chuáº©n hÃ³a khoáº£ng tráº¯ng

#### **B. Chá»n ÄÃºng Embedding Model**

**Cho tiáº¿ng Viá»‡t:**
- âœ… **BGE-M3** (Best): Äa ngÃ´n ngá»¯, há»— trá»£ tiáº¿ng Viá»‡t tá»‘t, 1024 dimensions
- âœ… **paraphrase-multilingual-MiniLM-L12-v2** (Good): Nháº¹, nhanh
- âœ… **multilingual-e5-large** (Excellent): Ráº¥t tá»‘t cho tiáº¿ng Viá»‡t
- âœ… **vietnamese-bert-base** (Specialized): ChuyÃªn cho tiáº¿ng Viá»‡t

**Khuyáº¿n nghá»‹:** BGE-M3 qua Ollama (báº¡n Ä‘Ã£ cÃ³)

#### **C. Context Enrichment (LÃ m GiÃ u Context)**

**Váº¥n Ä‘á»:** Má»™t cÃ¢u "KhÃ¡ch sáº¡n gáº§n biá»ƒn" cÃ³ thá»ƒ khÃ´ng match vá»›i "KhÃ¡ch sáº¡n ven biá»ƒn Má»¹ KhÃª" náº¿u embedding khÃ´ng Ä‘á»§ context.

**Giáº£i phÃ¡p:**

1. **ThÃªm synonyms vÃ  biáº¿n thá»ƒ:**
   ```
   "gáº§n biá»ƒn" â†’ "ven biá»ƒn, sÃ¡t biá»ƒn, cÃ¡ch biá»ƒn, view biá»ƒn, hÆ°á»›ng biá»ƒn"
   "5 sao" â†’ "5 sao, luxury, cao cáº¥p, sang trá»ng"
   "giÃ¡ ráº»" â†’ "giÃ¡ ráº», giÃ¡ tá»‘t, giÃ¡ há»£p lÃ½, giÃ¡ pháº£i chÄƒng"
   ```

2. **Expand query (má»Ÿ rá»™ng truy váº¥n):**
   - Sá»­ dá»¥ng LLM Ä‘á»ƒ má»Ÿ rá»™ng query ngÆ°á»i dÃ¹ng
   - VÃ­ dá»¥: "KhÃ¡ch sáº¡n gáº§n biá»ƒn" â†’ "KhÃ¡ch sáº¡n ven biá»ƒn, sÃ¡t biá»ƒn, view biá»ƒn, hÆ°á»›ng biá»ƒn"

3. **Hybrid Search (tÃ¬m kiáº¿m lai):**
   - Káº¿t há»£p **semantic search** (embedding) + **keyword search** (BM25)
   - LangChain há»— trá»£ qua `VectorStoreRetriever` + `BM25Retriever`

#### **D. Query Processing (Xá»­ LÃ½ Truy Váº¥n)**

**TrÆ°á»›c khi embedding query:**

1. **Chuáº©n hÃ³a query:**
   - Loáº¡i bá» stop words khÃ´ng cáº§n thiáº¿t
   - Giá»¯ láº¡i tá»« khÃ³a quan trá»ng
   - Xá»­ lÃ½ lá»—i chÃ­nh táº£ (náº¿u cÃ³)

2. **Query expansion:**
   ```python
   # VÃ­ dá»¥ vá»›i LangChain
   from langchain.retrievers import ContextualCompressionRetriever
   from langchain.retrievers.document_compressors import LLMChainExtractor
   
   # Expand query vá»›i LLM
   expanded_query = llm.expand_query("KhÃ¡ch sáº¡n gáº§n biá»ƒn")
   # â†’ "KhÃ¡ch sáº¡n ven biá»ƒn, sÃ¡t biá»ƒn Má»¹ KhÃª, view biá»ƒn, hÆ°á»›ng biá»ƒn"
   ```

3. **Query understanding:**
   - PhÃ¢n loáº¡i intent: "TÃ¬m khÃ¡ch sáº¡n" vs "So sÃ¡nh giÃ¡" vs "Xem Ä‘Ã¡nh giÃ¡"
   - Extract entities: "ÄÃ  Náºµng", "5 sao", "gáº§n biá»ƒn"

#### **E. Re-ranking (Sáº¯p Xáº¿p Láº¡i Káº¿t Quáº£)**

**Váº¥n Ä‘á»:** Top-k results tá»« embedding search cÃ³ thá»ƒ khÃ´ng chÃ­nh xÃ¡c 100%.

**Giáº£i phÃ¡p:**

1. **Cross-encoder re-ranking:**
   - Sá»­ dá»¥ng model cross-encoder (nhÆ° `ms-marco-MiniLM`) Ä‘á»ƒ re-rank
   - So sÃ¡nh query vá»›i tá»«ng document má»™t cÃ¡ch chÃ­nh xÃ¡c hÆ¡n

2. **Multi-stage retrieval:**
   ```
   Stage 1: Embedding search â†’ Top 50 results
   Stage 2: Re-rank vá»›i cross-encoder â†’ Top 10 results
   Stage 3: LLM refine â†’ Top 5 results
   ```

3. **Hybrid scoring:**
   - Káº¿t há»£p: `final_score = 0.7 * semantic_score + 0.3 * keyword_score`

---

## ğŸ—ï¸ 3. PHÆ¯Æ NG PHÃP THIáº¾T Káº¾ PIPELINE RAG Vá»šI LANGCHAIN

### **3.1 Kiáº¿n TrÃºc Tá»•ng Quan**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    USER QUERY                               â”‚
â”‚          "KhÃ¡ch sáº¡n 5 sao gáº§n biá»ƒn ÄÃ  Náºµng"                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              QUERY PROCESSING LAYER                        â”‚
â”‚  â€¢ Query normalization                                      â”‚
â”‚  â€¢ Query expansion (LLM)                                    â”‚
â”‚  â€¢ Intent classification                                     â”‚
â”‚  â€¢ Entity extraction                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              EMBEDDING LAYER                                 â”‚
â”‚  â€¢ Local Embedding Model (BGE-M3 via Ollama)                â”‚
â”‚  â€¢ Query â†’ Vector                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              RETRIEVAL LAYER                                 â”‚
â”‚  â€¢ Vector Store (Qdrant) - Semantic Search                  â”‚
â”‚  â€¢ BM25 Retriever (optional) - Keyword Search                â”‚
â”‚  â€¢ Hybrid Search (combine both)                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              RE-RANKING LAYER (Optional)                     â”‚
â”‚  â€¢ Cross-encoder re-ranking                                 â”‚
â”‚  â€¢ Score refinement                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              CONTEXT ENRICHMENT                              â”‚
â”‚  â€¢ Join with related tables (room, type_room, area, brand)  â”‚
â”‚  â€¢ Format context for LLM                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              LLM GENERATION LAYER                            â”‚
â”‚  â€¢ Local LLM (Ollama: llama2, mistral, etc.)               â”‚
â”‚  â€¢ Prompt template vá»›i context                               â”‚
â”‚  â€¢ Generate natural language response                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              RESPONSE                                        â”‚
â”‚  â€¢ Natural language answer                                   â”‚
â”‚  â€¢ Structured data (hotel list)                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### **3.2 CÃ¡c ThÃ nh Pháº§n LangChain Cáº§n DÃ¹ng**

#### **A. Document Loaders & Processors**
```python
# Load CSV files
from langchain_community.document_loaders import CSVLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter

# Táº¡o documents tá»« CSV
documents = []
for hotel in hotels_df:
    # Combine multiple fields
    text = f"TÃªn: {hotel_name} | MÃ´ táº£: {hotel_desc} | ..."
    documents.append(Document(page_content=text, metadata={hotel_id, ...}))
```

#### **B. Embeddings**
```python
from langchain_community.embeddings import OllamaEmbeddings

# Local embedding via Ollama
embeddings = OllamaEmbeddings(
    model="bge-m3",
    base_url="http://localhost:11434"
)
```

#### **C. Vector Store**
```python
from langchain_community.vectorstores import Qdrant
from langchain.vectorstores import Qdrant

# Connect to Qdrant
vectorstore = Qdrant.from_documents(
    documents=documents,
    embedding=embeddings,
    url="http://localhost:6333",
    collection_name="hotels"
)
```

#### **D. Retrievers**
```python
from langchain.retrievers import VectorStoreRetriever
from langchain.retrievers import BM25Retriever
from langchain.retrievers import EnsembleRetriever

# Semantic retriever
vector_retriever = VectorStoreRetriever(vectorstore=vectorstore)

# Keyword retriever (optional)
bm25_retriever = BM25Retriever.from_documents(documents)

# Hybrid retriever
ensemble_retriever = EnsembleRetriever(
    retrievers=[vector_retriever, bm25_retriever],
    weights=[0.7, 0.3]  # 70% semantic, 30% keyword
)
```

#### **E. LLM**
```python
from langchain_community.llms import Ollama

# Local LLM via Ollama
llm = Ollama(
    model="llama2",  # or "mistral", "phi", "gemma"
    base_url="http://localhost:11434",
    temperature=0.7
)
```

#### **F. Chains**
```python
from langchain.chains import RetrievalQA
from langchain.chains import ConversationalRetrievalChain
from langchain.prompts import PromptTemplate

# Prompt template
prompt_template = """
Báº¡n lÃ  trá»£ lÃ½ tÆ° váº¥n khÃ¡ch sáº¡n chuyÃªn nghiá»‡p.

Context: {context}

CÃ¢u há»i: {question}

HÃ£y tráº£ lá»i dá»±a trÃªn context trÃªn. Náº¿u khÃ´ng cÃ³ thÃ´ng tin, hÃ£y nÃ³i "TÃ´i khÃ´ng cÃ³ thÃ´ng tin vá» Ä‘iá»u nÃ y."
"""

# RAG Chain
qa_chain = RetrievalQA.from_chain_type(
    llm=llm,
    chain_type="stuff",
    retriever=ensemble_retriever,
    chain_type_kwargs={"prompt": PromptTemplate.from_template(prompt_template)}
)
```

---

## ğŸ“Š 4. PHÆ¯Æ NG PHÃP Xá»¬ LÃ DATASET KHÃCH Sáº N

### **4.1 Chuáº©n Bá»‹ Dá»¯ Liá»‡u**

#### **BÆ°á»›c 1: Load vÃ  Join Tables**
```
tbl_hotel (main)
    â”œâ”€â”€ JOIN tbl_room (hotel_id)
    â”‚   â””â”€â”€ JOIN tbl_type_room (room_id)
    â”œâ”€â”€ JOIN tbl_area (area_id)
    â”œâ”€â”€ JOIN tbl_brand (brand_id)
    â””â”€â”€ JOIN tbl_coupon (náº¿u cáº§n)
```

#### **BÆ°á»›c 2: Táº¡o Document cho má»—i Hotel**
```
Document Structure:
{
    "page_content": "TÃªn: MeliÃ¡ Vinpearl Riverfront | 
                    MÃ´ táº£: KhÃ¡ch sáº¡n 5 sao cao cáº¥p... | 
                    Äá»‹a chá»‰: 341 Tráº§n HÆ°ng Äáº¡o... | 
                    Khu vá»±c: SÆ¡n TrÃ  | 
                    ThÆ°Æ¡ng hiá»‡u: Furama | 
                    Tá»« khÃ³a: KhÃ¡ch Sáº¡n ÄÃ  Náºµng, 5 Sao | 
                    Háº¡ng: 5 sao | 
                    GiÃ¡: 1,311,127 VND | 
                    PhÃ²ng: Grand Suite (45mÂ², HÆ°á»›ng SÃ´ng) | 
                    ...",
    "metadata": {
        "hotel_id": 2,
        "hotel_name": "MeliÃ¡ Vinpearl Riverfront",
        "area_id": 8,
        "brand_id": 3,
        "hotel_rank": 5,
        "hotel_price_average": 1311127
    }
}
```

#### **BÆ°á»›c 3: Chunk Documents (náº¿u cáº§n)**
- Náº¿u hotel description quÃ¡ dÃ i (>512 tokens), chia nhá»
- NhÆ°ng vá»›i dataset cá»§a báº¡n, má»—i hotel cÃ³ thá»ƒ fit trong 1 document

### **4.2 Index vÃ o Vector Store**

```
1. Load documents tá»« CSV
2. Process vÃ  enrich vá»›i metadata
3. Embed vá»›i local model (BGE-M3)
4. Store vÃ o Qdrant vá»›i metadata
```

### **4.3 Query Processing**

**VÃ­ dá»¥ queries:**
- "KhÃ¡ch sáº¡n 5 sao gáº§n biá»ƒn ÄÃ  Náºµng"
- "KhÃ¡ch sáº¡n giÃ¡ ráº» á»Ÿ SÆ¡n TrÃ "
- "So sÃ¡nh giÃ¡ khÃ¡ch sáº¡n MÆ°á»ng Thanh vÃ  MeliÃ¡"

**Xá»­ lÃ½:**
1. **Intent classification:**
   - TÃ¬m kiáº¿m â†’ Semantic search
   - So sÃ¡nh â†’ Multi-document comparison
   - TÆ° váº¥n â†’ RAG generation

2. **Entity extraction:**
   - "5 sao" â†’ hotel_rank = 5
   - "gáº§n biá»ƒn" â†’ room_view = "HÆ°á»›ng SÃ´ng" hoáº·c keyword "biá»ƒn"
   - "ÄÃ  Náºµng" â†’ area_name = "SÆ¡n TrÃ " (cÃ³ thá»ƒ)
   - "giÃ¡ ráº»" â†’ price filter

3. **Query expansion:**
   ```
   "KhÃ¡ch sáº¡n 5 sao gáº§n biá»ƒn" 
   â†’ "KhÃ¡ch sáº¡n 5 sao ven biá»ƒn, sÃ¡t biá»ƒn, view biá»ƒn, hÆ°á»›ng biá»ƒn"
   ```

### **4.4 Retrieval Strategy**

#### **Option 1: Pure Semantic Search**
```
Query â†’ Embedding â†’ Vector Search â†’ Top-k results
```

#### **Option 2: Hybrid Search (Recommended)**
```
Query â†’ {
    Semantic: Embedding â†’ Vector Search (top 50)
    Keyword: BM25 Search (top 50)
} â†’ Merge & Deduplicate â†’ Top-k results
```

#### **Option 3: Multi-stage Retrieval**
```
Stage 1: Semantic Search (top 50)
Stage 2: Re-rank vá»›i cross-encoder (top 10)
Stage 3: LLM refine (top 5)
```

### **4.5 Response Generation**

**Prompt Template:**
```
Báº¡n lÃ  trá»£ lÃ½ tÆ° váº¥n khÃ¡ch sáº¡n chuyÃªn nghiá»‡p.

Dá»±a trÃªn thÃ´ng tin sau, hÃ£y tráº£ lá»i cÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng:

{context}

CÃ¢u há»i: {question}

HÃ£y:
1. Tráº£ lá»i tá»± nhiÃªn, dá»… hiá»ƒu
2. NÃªu tÃªn khÃ¡ch sáº¡n, Ä‘á»‹a chá»‰, giÃ¡ náº¿u cÃ³
3. Náº¿u khÃ´ng cÃ³ thÃ´ng tin, hÃ£y nÃ³i rÃµ
```

---

## ğŸ”§ 5. Cáº¢I THIá»†N Äá»˜ CHÃNH XÃC TÃŒM KIáº¾M

### **5.1 Fine-tuning Embedding Model (Advanced)**

Náº¿u dataset Ä‘á»§ lá»›n, cÃ³ thá»ƒ fine-tune embedding model:
- Train trÃªn cáº·p (query, relevant_hotel)
- Sá»­ dá»¥ng contrastive learning
- Cáº£i thiá»‡n Ä‘Ã¡ng ká»ƒ Ä‘á»™ chÃ­nh xÃ¡c

### **5.2 Query Augmentation**

**Techniques:**
1. **Paraphrasing:** Táº¡o nhiá»u biáº¿n thá»ƒ cá»§a query
2. **Back-translation:** Dá»‹ch query sang tiáº¿ng Anh rá»“i dá»‹ch láº¡i
3. **Synonym expansion:** Má»Ÿ rá»™ng tá»« Ä‘á»“ng nghÄ©a

### **5.3 Metadata Filtering**

Sá»­ dá»¥ng metadata Ä‘á»ƒ filter trÆ°á»›c khi search:
```python
# Filter by area, brand, rank, price range
filtered_results = vectorstore.similarity_search(
    query,
    filter={
        "area_id": 8,
        "hotel_rank": 5,
        "price_range": {"$gte": 1000000, "$lte": 2000000}
    }
)
```

### **5.4 Evaluation Metrics**

Äá»ƒ Ä‘Ã¡nh giÃ¡ cháº¥t lÆ°á»£ng:
- **Precision@K:** % káº¿t quáº£ Ä‘Ãºng trong top-k
- **Recall@K:** % káº¿t quáº£ Ä‘Ãºng Ä‘Æ°á»£c tÃ¬m tháº¥y
- **MRR (Mean Reciprocal Rank):** Vá»‹ trÃ­ trung bÃ¬nh cá»§a káº¿t quáº£ Ä‘Ãºng Ä‘áº§u tiÃªn
- **NDCG (Normalized Discounted Cumulative Gain):** ÄÃ¡nh giÃ¡ cháº¥t lÆ°á»£ng ranking

---

## ğŸ“ 6. LUá»’NG Xá»¬ LÃ CHI TIáº¾T

### **6.1 Initialization Phase**

```
1. Load embedding model (BGE-M3 via Ollama)
2. Load LLM model (llama2/mistral via Ollama)
3. Connect to Qdrant
4. Load documents tá»« CSV
5. Process vÃ  enrich documents
6. Embed documents
7. Index vÃ o Qdrant
```

### **6.2 Query Phase**

```
1. Receive user query
2. Query preprocessing (normalize, expand)
3. Embed query
4. Semantic search in Qdrant
5. (Optional) Keyword search with BM25
6. Merge results
7. (Optional) Re-rank
8. Join with related tables (room, area, brand)
9. Format context
10. Generate response vá»›i LLM
11. Return response
```

### **6.3 Update Phase**

```
1. Receive new hotel data
2. Process vÃ  enrich
3. Embed
4. Add to Qdrant (incremental update)
```

---

## ğŸ¯ 7. KHUYáº¾N NGHá»Š CHO DATASET Cá»¦A Báº N

### **7.1 Embedding Model**
âœ… **BGE-M3** (Ä‘Ã£ cÃ³) - Ráº¥t tá»‘t cho tiáº¿ng Viá»‡t

### **7.2 LLM Model**
âœ… **llama2:7b** hoáº·c **mistral:7b** - Äá»§ tá»‘t cho RAG
- Náº¿u muá»‘n tá»‘t hÆ¡n: **llama2:13b** hoáº·c **mistral:8x7b**

### **7.3 Retrieval Strategy**
âœ… **Hybrid Search** (Semantic + Keyword) - Best balance

### **7.4 Re-ranking**
âš ï¸ **Optional** - Náº¿u cáº§n Ä‘á»™ chÃ­nh xÃ¡c cao hÆ¡n

### **7.5 Document Structure**
âœ… **Má»—i hotel = 1 document** vá»›i Ä‘áº§y Ä‘á»§ metadata

---

## ğŸš€ 8. Lá»¢I ÃCH KHI DÃ™NG LANGCHAIN

### **8.1 Modularity**
- Dá»… thay Ä‘á»•i tá»«ng component (embedding, LLM, retriever)
- Dá»… test vÃ  debug

### **8.2 Built-in Features**
- Prompt templates
- Chains (RAG, QA, Conversation)
- Memory management
- Callbacks & logging

### **8.3 Integration**
- Dá»… tÃ­ch há»£p vá»›i cÃ¡c tools khÃ¡c
- Há»— trá»£ nhiá»u vector stores
- Há»— trá»£ nhiá»u LLM providers

### **8.4 Community & Support**
- TÃ i liá»‡u phong phÃº
- Nhiá»u examples
- Active community

---

## ğŸ“š 9. TÃ€I LIá»†U THAM KHáº¢O

### **LangChain Documentation**
- https://python.langchain.com/
- https://python.langchain.com/docs/integrations/vectorstores/qdrant
- https://python.langchain.com/docs/integrations/llms/ollama

### **Embedding Models**
- BGE-M3: https://huggingface.co/BAAI/bge-m3
- Sentence Transformers: https://www.sbert.net/

### **Vector Databases**
- Qdrant: https://qdrant.tech/documentation/
- Milvus: https://milvus.io/docs

---

## âœ… Káº¾T LUáº¬N

**CÃ¢u tráº£ lá»i:**
1. âœ… **CÃ³ thá»ƒ dÃ¹ng LangChain vá»›i local models** - HoÃ n toÃ n kháº£ thi
2. âœ… **Embedding sáº½ hiá»ƒu ngá»¯ nghÄ©a tá»‘t** náº¿u:
   - Chuáº©n hÃ³a dá»¯ liá»‡u Ä‘Ãºng cÃ¡ch
   - Chá»n Ä‘Ãºng model
   - Enrich context Ä‘áº§y Ä‘á»§
   - Xá»­ lÃ½ query tá»‘t
   - (Optional) Re-ranking

3. âœ… **PhÆ°Æ¡ng phÃ¡p tá»‘t nháº¥t:**
   - LangChain + Ollama (embedding + LLM)
   - Qdrant (vector store)
   - Hybrid search (semantic + keyword)
   - RAG chain vá»›i prompt template

**BÆ°á»›c tiáº¿p theo:** Implement theo phÆ°Æ¡ng phÃ¡p trÃªn, test vÃ  fine-tune!

